{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fs5Hm1oh9B6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hi9eFsgikkY",
        "outputId": "6c8ea841-44cb-4720-8783-cffa2faed84f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "movie_lines_df = pd.read_csv('movie_lines.txt', sep=' \\+\\+\\+\\$\\+\\+\\+ ', encoding='unicode_escape', names=['lineID','charID','movieID','char_name','utter'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_df = movie_lines_df[:10000].dropna()"
      ],
      "metadata": {
        "id": "LYU1s-L_TTBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создание сортированного словаря по возрастанию с парами (номер фразы: фраза)\n",
        "def get_all_sorted_chats(all_conversations):\n",
        "    all_chats = {}\n",
        "    for tokens in all_conversations.values:\n",
        "        all_chats[int(tokens[0][1:])] = tokens[4]\n",
        "    return sorted(all_chats.items(), key=lambda x: x[0])"
      ],
      "metadata": {
        "id": "42jiif7DTBSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание словаря с попарными диалогами\n",
        "def get_conversation_dict(sorted_chats):\n",
        "  conv_dict = {}\n",
        "  counter = 1\n",
        "  conv_ids = [] # список текущего диалога\n",
        "  for i in range(1, len(sorted_chats) + 1):\n",
        "    if i < len(sorted_chats):\n",
        "        # если номер текущей строки отличается от предыдущего на 1\n",
        "        # то эта строка является частью текущего диалога\n",
        "      if (sorted_chats[i][0] - sorted_chats[i - 1][0]) == 1:\n",
        "          # если предыдущая строка не была добавлена ​​ранее, \n",
        "          # то мы должны добавить ее сейчас\n",
        "        if sorted_chats[i - 1][1] not in conv_ids:\n",
        "          conv_ids.append(sorted_chats[i - 1][1])\n",
        "        conv_ids.append(sorted_chats[i][1]) # или просто добавьте текущую строку\n",
        "            # а если разница больше 1 - значит новый разговор начался \n",
        "            # и надо очистить conv_ids\n",
        "      elif (sorted_chats[i][0] - sorted_chats[i - 1][0]) > 1:\n",
        "        conv_dict[counter] = conv_ids\n",
        "        conv_ids = []\n",
        "        counter += 1\n",
        "      else: continue\n",
        "  return conv_dict"
      ],
      "metadata": {
        "id": "h05_iovIS6Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Форматирование и очистка текста\n",
        "def clean_text(text_to_clean):\n",
        "    res = text_to_clean.lower()\n",
        "    res = re.sub(r\"i'm\", \"i am\", res)\n",
        "    res = re.sub(r\"he's\", \"he is\", res)\n",
        "    res = re.sub(r\"she's\", \"she is\", res)\n",
        "    res = re.sub(r\"it's\", \"it is\", res)\n",
        "    res = re.sub(r\"that's\", \"that is\", res)\n",
        "    res = re.sub(r\"what's\", \"what is\", res)\n",
        "    res = re.sub(r\"where's\", \"where is\", res)\n",
        "    res = re.sub(r\"how's\", \"how is\", res)\n",
        "    res = re.sub(r\"\\'ll\", \" will\", res)\n",
        "    res = re.sub(r\"\\'ve\", \" have\", res)\n",
        "    res = re.sub(r\"\\'re\", \" are\", res)\n",
        "    res = re.sub(r\"\\'d\", \" would\", res)\n",
        "    res = re.sub(r\"\\'re\", \" are\", res)\n",
        "    res = re.sub(r\"won't\", \"will not\", res)\n",
        "    res = re.sub(r\"can't\", \"cannot\", res)\n",
        "    res = re.sub(r\"n't\", \" not\", res)\n",
        "    res = re.sub(r\"n'\", \"ng\", res)\n",
        "    res = re.sub(r\"'bout\", \"about\", res)\n",
        "    res = re.sub(r\"'til\", \"until\", res)\n",
        "    res = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", res)\n",
        "    return res"
      ],
      "metadata": {
        "id": "Una2jyjRVg4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_clean_q_and_a(conversations_dictionary):\n",
        "    ctx_and_target = []\n",
        "    for current_conv in conversations_dictionary.values():\n",
        "        # проверка диалога на четное количество строк\n",
        "        if len(current_conv) % 2 != 0:\n",
        "            current_conv = current_conv[:-1]\n",
        "        # создание кортежей с вопросами и ответами\n",
        "        for i in range(0, len(current_conv), 2):\n",
        "            ctx_and_target.append((current_conv[i], current_conv[i + 1]))\n",
        "    # с пмощью zip с оператором * \n",
        "    # распаковываем кортежи в 2 независимых списка вопросов и ответов\n",
        "    context, target = zip(*ctx_and_target)\n",
        "    context_dirty = list(context)\n",
        "    target_dirty = list(target)\n",
        "\n",
        "    # очищаем вопросы от сокращенных форм, \n",
        "    # небуквенных символов и преобразовать их в нижний регистр\n",
        "    clean_questions = list()\n",
        "    for i in range(len(context_dirty)):\n",
        "        clean_questions.append(clean_text(context_dirty[i]))\n",
        "\n",
        "    # делаем то же самое с ответами\n",
        "    # и добаляем токены старта и финиша ответа\n",
        "    clean_answers = list()\n",
        "    for i in range(len(target_dirty)):\n",
        "        clean_answers.append('<START> '+ clean_text(target_dirty[i]) + ' <END>')\n",
        "        \n",
        "    return clean_questions, clean_answers"
      ],
      "metadata": {
        "id": "u0PfLhJyVkCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_conv = get_all_sorted_chats(conv_df)\n",
        "conv_dict = get_conversation_dict(all_conv)\n",
        "df_m_1, df_f_1 = get_clean_q_and_a(conv_dict)"
      ],
      "metadata": {
        "id": "W70at-D7VpUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz3loXqtg1eb",
        "outputId": "1723ac9e-c57b-4a20-db8f-33ce0a68db1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size : 7940\n"
          ]
        }
      ],
      "source": [
        "from keras_preprocessing.text import Tokenizer\n",
        "\n",
        "target_regex = '!\"#$%&()*+,-./:;=?@[\\]^_`{|}~\\t\\n\\'0123456789'\n",
        "# Tokenizer позволяет векторизовать наш корпус, превращая каждое предложение\n",
        "# в последовательность целых чисел, где каждое целое число является индексом\n",
        "# токена во внутреннем словаре\n",
        "tokenizer = Tokenizer(filters=target_regex)\n",
        "tokenizer.fit_on_texts(df_m_1 + df_f_1)\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "print('Размер словаря : {}'.format(VOCAB_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFvEY4WwhZXO",
        "outputId": "82e0b79b-103e-4dd8-9498-4b7a0bc51805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4707, 223)\n",
            "(4707, 132)\n"
          ]
        }
      ],
      "source": [
        "tokenized_questions = tokenizer.texts_to_sequences(df_m_1)\n",
        "maxlen_questions = max([len(x) for x in tokenized_questions]) # максимальная длина вопроса\n",
        "\n",
        "# делаем паддинг для всех вопросов которые короче самого длинного вопроса\n",
        "encoder_input_data = tf.keras.utils.pad_sequences(tokenized_questions, \n",
        "                                 maxlen=maxlen_questions,\n",
        "                                 padding='post')\n",
        "print(f'Количество вопросов: {encoder_input_data.shape[0]} Длина вопросов: {encoder_input_data.shape[1]}')\n",
        "\n",
        "tokenized_answers = tokenizer.texts_to_sequences(df_f_1)\n",
        "maxlen_answers = max([len(x) for x in tokenized_answers]) # максимальная длина ответа\n",
        "\n",
        "# делаем паддинг для всех ответов которые короче самого длинного вопроса\n",
        "decoder_input_data = tf.keras.utils.pad_sequences(tokenized_answers,   \n",
        "                                   maxlen=maxlen_answers,\n",
        "                                   padding='post')\n",
        "print(f'Количество ответов: {decoder_input_data.shape[0]} Длина ответов: {decoder_input_data.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cjh5SPpiMFx"
      },
      "outputs": [],
      "source": [
        "# Убрать <start> в начале ответов\n",
        "for i in range(len(tokenized_answers)):\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "decoder_output = tf.keras.utils.pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnbQz8yuiWUc"
      },
      "outputs": [],
      "source": [
        "H_SIZE = 256 # Размерность скрытого состояния LSTM\n",
        "EMB_SIZE = 256 # размерность эмбеддингов (и для входных и для выходных цепочек)\n",
        "\n",
        "# Encoder\n",
        "enc_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "enc_embedding = tf.keras.layers.Embedding(VOCAB_SIZE, EMB_SIZE, mask_zero=True)(enc_inputs)\n",
        "\n",
        "enc_outputs, state_h, state_c = tf.keras.layers.LSTM(H_SIZE, return_sequences=False, return_state=True)(enc_embedding)\n",
        "enc_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "dec_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "dec_embedding = tf.keras.layers.Embedding(VOCAB_SIZE, EMB_SIZE, mask_zero=True)(dec_inputs)\n",
        "\n",
        "dec_lstm = tf.keras.layers.LSTM(H_SIZE, return_state=True, return_sequences=True)\n",
        "dec_outputs, _, _ = dec_lstm(dec_embedding, initial_state=enc_states)\n",
        "\n",
        "dec_dense = tf.keras.layers.Dense(VOCAB_SIZE, activation='softmax')\n",
        "output = dec_dense(dec_outputs)\n",
        "\n",
        "#Создание модели для обучения\n",
        "model = tf.keras.Model([enc_inputs, dec_inputs], output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "model.compile(optimizer='rmsprop', loss=loss)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xbn4WVCG3IF_",
        "outputId": "96248dbf-ec70-4af8-e1fd-87bfd208c8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_19 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_20 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)        (None, None, 256)    2032640     ['input_19[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)        (None, None, 256)    2032640     ['input_20[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_6 (LSTM)                  [(None, 256),        525312      ['embedding_6[0][0]']            \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_7 (LSTM)                  [(None, None, 256),  525312      ['embedding_7[0][0]',            \n",
            "                                 (None, 256),                     'lstm_6[0][1]',                 \n",
            "                                 (None, 256)]                     'lstm_6[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, None, 7940)   2040580     ['lstm_7[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,156,484\n",
            "Trainable params: 7,156,484\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxpU2YT4i4Do",
        "outputId": "54ad82d6-c0bd-48ae-b172-a625b9ce9af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "74/74 [==============================] - 12s 65ms/step - loss: 0.5692\n",
            "Epoch 2/150\n",
            "74/74 [==============================] - 5s 63ms/step - loss: 0.5053\n",
            "Epoch 3/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.4855\n",
            "Epoch 4/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.4707\n",
            "Epoch 5/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.4590\n",
            "Epoch 6/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.4480\n",
            "Epoch 7/150\n",
            "74/74 [==============================] - 5s 64ms/step - loss: 0.4378\n",
            "Epoch 8/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.4290\n",
            "Epoch 9/150\n",
            "74/74 [==============================] - 5s 64ms/step - loss: 0.4211\n",
            "Epoch 10/150\n",
            "74/74 [==============================] - 5s 64ms/step - loss: 0.4132\n",
            "Epoch 11/150\n",
            "74/74 [==============================] - 5s 64ms/step - loss: 0.4060\n",
            "Epoch 12/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.3988\n",
            "Epoch 13/150\n",
            "74/74 [==============================] - 5s 63ms/step - loss: 0.3916\n",
            "Epoch 14/150\n",
            "74/74 [==============================] - 5s 64ms/step - loss: 0.3848\n",
            "Epoch 15/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.3780\n",
            "Epoch 16/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.3709\n",
            "Epoch 17/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.3639\n",
            "Epoch 18/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.3570\n",
            "Epoch 19/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.3498\n",
            "Epoch 20/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.3428\n",
            "Epoch 21/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.3352\n",
            "Epoch 22/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.3278\n",
            "Epoch 23/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.3209\n",
            "Epoch 24/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.3133\n",
            "Epoch 25/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.3059\n",
            "Epoch 26/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.2984\n",
            "Epoch 27/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.2907\n",
            "Epoch 28/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.2831\n",
            "Epoch 29/150\n",
            "74/74 [==============================] - 5s 64ms/step - loss: 0.2755\n",
            "Epoch 30/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.2682\n",
            "Epoch 31/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.2606\n",
            "Epoch 32/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.2531\n",
            "Epoch 33/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.2460\n",
            "Epoch 34/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.2381\n",
            "Epoch 35/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.2312\n",
            "Epoch 36/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.2235\n",
            "Epoch 37/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.2166\n",
            "Epoch 38/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.2094\n",
            "Epoch 39/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.2025\n",
            "Epoch 40/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.1954\n",
            "Epoch 41/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.1882\n",
            "Epoch 42/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.1814\n",
            "Epoch 43/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.1749\n",
            "Epoch 44/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.1682\n",
            "Epoch 45/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.1616\n",
            "Epoch 46/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.1554\n",
            "Epoch 47/150\n",
            "74/74 [==============================] - 5s 59ms/step - loss: 0.1489\n",
            "Epoch 48/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.1430\n",
            "Epoch 49/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.1370\n",
            "Epoch 50/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.1312\n",
            "Epoch 51/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.1255\n",
            "Epoch 52/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.1201\n",
            "Epoch 53/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.1147\n",
            "Epoch 54/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.1093\n",
            "Epoch 55/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.1043\n",
            "Epoch 56/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0995\n",
            "Epoch 57/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0944\n",
            "Epoch 58/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0900\n",
            "Epoch 59/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0856\n",
            "Epoch 60/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0812\n",
            "Epoch 61/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0770\n",
            "Epoch 62/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0731\n",
            "Epoch 63/150\n",
            "74/74 [==============================] - 8s 105ms/step - loss: 0.0695\n",
            "Epoch 64/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0654\n",
            "Epoch 65/150\n",
            "74/74 [==============================] - 5s 71ms/step - loss: 0.0620\n",
            "Epoch 66/150\n",
            "74/74 [==============================] - 6s 83ms/step - loss: 0.0584\n",
            "Epoch 67/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0550\n",
            "Epoch 68/150\n",
            "74/74 [==============================] - 6s 76ms/step - loss: 0.0521\n",
            "Epoch 69/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0490\n",
            "Epoch 70/150\n",
            "74/74 [==============================] - 5s 73ms/step - loss: 0.0460\n",
            "Epoch 71/150\n",
            "74/74 [==============================] - 6s 78ms/step - loss: 0.0433\n",
            "Epoch 72/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0408\n",
            "Epoch 73/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0383\n",
            "Epoch 74/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0360\n",
            "Epoch 75/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0338\n",
            "Epoch 76/150\n",
            "74/74 [==============================] - 5s 73ms/step - loss: 0.0315\n",
            "Epoch 77/150\n",
            "74/74 [==============================] - 5s 74ms/step - loss: 0.0296\n",
            "Epoch 78/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0278\n",
            "Epoch 79/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0260\n",
            "Epoch 80/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0241\n",
            "Epoch 81/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0227\n",
            "Epoch 82/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0214\n",
            "Epoch 83/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0198\n",
            "Epoch 84/150\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0186\n",
            "Epoch 85/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0173\n",
            "Epoch 86/150\n",
            "74/74 [==============================] - 6s 76ms/step - loss: 0.0161\n",
            "Epoch 87/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0153\n",
            "Epoch 88/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0141\n",
            "Epoch 89/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.0132\n",
            "Epoch 90/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0124\n",
            "Epoch 91/150\n",
            "74/74 [==============================] - 5s 71ms/step - loss: 0.0117\n",
            "Epoch 92/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0109\n",
            "Epoch 93/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0103\n",
            "Epoch 94/150\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 0.0097\n",
            "Epoch 95/150\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 0.0089\n",
            "Epoch 96/150\n",
            "74/74 [==============================] - 7s 90ms/step - loss: 0.0085\n",
            "Epoch 97/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0080\n",
            "Epoch 98/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0075\n",
            "Epoch 99/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0071\n",
            "Epoch 100/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0069\n",
            "Epoch 101/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0067\n",
            "Epoch 102/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0060\n",
            "Epoch 103/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0058\n",
            "Epoch 104/150\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.0055\n",
            "Epoch 105/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0054\n",
            "Epoch 106/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0052\n",
            "Epoch 107/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0049\n",
            "Epoch 108/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0046\n",
            "Epoch 109/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0045\n",
            "Epoch 110/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0043\n",
            "Epoch 111/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0042\n",
            "Epoch 112/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0040\n",
            "Epoch 113/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0038\n",
            "Epoch 114/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0038\n",
            "Epoch 115/150\n",
            "74/74 [==============================] - 6s 78ms/step - loss: 0.0037\n",
            "Epoch 116/150\n",
            "74/74 [==============================] - 7s 95ms/step - loss: 0.0037\n",
            "Epoch 117/150\n",
            "74/74 [==============================] - 6s 84ms/step - loss: 0.0035\n",
            "Epoch 118/150\n",
            "74/74 [==============================] - 6s 88ms/step - loss: 0.0035\n",
            "Epoch 119/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0034\n",
            "Epoch 120/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0032\n",
            "Epoch 121/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0031\n",
            "Epoch 122/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0031\n",
            "Epoch 123/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0030\n",
            "Epoch 124/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0030\n",
            "Epoch 125/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0029\n",
            "Epoch 126/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0028\n",
            "Epoch 127/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0029\n",
            "Epoch 128/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0028\n",
            "Epoch 129/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0027\n",
            "Epoch 130/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0028\n",
            "Epoch 131/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0027\n",
            "Epoch 132/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0027\n",
            "Epoch 133/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0027\n",
            "Epoch 134/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0027\n",
            "Epoch 135/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0025\n",
            "Epoch 136/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0026\n",
            "Epoch 137/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0025\n",
            "Epoch 138/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0025\n",
            "Epoch 139/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0025\n",
            "Epoch 140/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0025\n",
            "Epoch 141/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0025\n",
            "Epoch 142/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0024\n",
            "Epoch 143/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0024\n",
            "Epoch 144/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0025\n",
            "Epoch 145/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0024\n",
            "Epoch 146/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0023\n",
            "Epoch 147/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0024\n",
            "Epoch 148/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0023\n",
            "Epoch 149/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0023\n",
            "Epoch 150/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0023\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffaa94f5c70>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], \n",
        "          decoder_output, \n",
        "          batch_size=64, \n",
        "          epochs=150)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_chat.h5') # сохраниение обученной модели"
      ],
      "metadata": {
        "id": "UYhBQU5dVarC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Функция конвертирования строки в токены\n",
        "def str_to_tokens(inp_str: str):\n",
        "    words = inp_str.lower().split()\n",
        "    tokens_list = list()\n",
        "    for current_word in words:\n",
        "        result = tokenizer.word_index.get(current_word, '')\n",
        "        if result != '':\n",
        "            tokens_list.append(result)\n",
        "    return tf.keras.utils.pad_sequences([tokens_list],\n",
        "                         maxlen=maxlen_questions,\n",
        "                         padding='post')"
      ],
      "metadata": {
        "id": "Cd8Dq-9J3rcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание моделей для инференса\n",
        "def make_inference_models():\n",
        "    dec_state_input_h = tf.keras.layers.Input(shape=(H_SIZE,))\n",
        "    dec_state_input_c = tf.keras.layers.Input(shape=(H_SIZE,))\n",
        "    dec_states_inputs = [dec_state_input_h, dec_state_input_c]\n",
        "\n",
        "    dec_outputs, state_h, state_c = dec_lstm(dec_embedding, initial_state=dec_states_inputs)\n",
        "    dec_states = [state_h, state_c]\n",
        "\n",
        "    dec_outputs = dec_dense(dec_outputs)\n",
        "\n",
        "    dec_model = tf.keras.Model(\n",
        "        inputs=[dec_inputs, dec_states_inputs],\n",
        "        outputs=[dec_outputs, dec_states])\n",
        "    print('Inference decoder:')\n",
        "    dec_model.summary()\n",
        "\n",
        "    print('Inference encoder:')\n",
        "    enc_model = tf.keras.Model(inputs=enc_inputs, outputs=enc_states)\n",
        "    enc_model.summary()\n",
        "\n",
        "    return enc_model, dec_model\n",
        "\n",
        "enc_model, dec_model = make_inference_models()"
      ],
      "metadata": {
        "id": "bvy1sSUx3amw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3eb94f9-cfff-486b-a7ca-754de89d5386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference decoder:\n",
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_20 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)        (None, None, 256)    2032640     ['input_20[0][0]']               \n",
            "                                                                                                  \n",
            " input_61 (InputLayer)          [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " input_62 (InputLayer)          [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_7 (LSTM)                  [(None, None, 256),  525312      ['embedding_7[0][0]',            \n",
            "                                 (None, 256),                     'input_61[0][0]',               \n",
            "                                 (None, 256)]                     'input_62[0][0]']               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, None, 7940)   2040580     ['lstm_7[2][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,598,532\n",
            "Trainable params: 4,598,532\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Inference encoder:\n",
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_19 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, None, 256)         2032640   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               [(None, 256),             525312    \n",
            "                              (None, 256),                       \n",
            "                              (None, 256)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,557,952\n",
            "Trainable params: 2,557,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Инференс\n",
        "for _ in range(10):\n",
        "    states_values = enc_model(str_to_tokens(input('Enter question : ')))\n",
        "    \n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index.get('start')\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        pred_input = [empty_target_seq] + states_values\n",
        "        dec_outputs, dec_states = dec_model(pred_input)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = tokenizer.index_word.get(sampled_word_index)\n",
        "        \n",
        "        if sampled_word != '<end>':\n",
        "          decoded_translation += ' {}'.format(sampled_word)\n",
        "        \n",
        "        if sampled_word == '<end>' or len(decoded_translation.split()) > maxlen_answers:\n",
        "                stop_condition = True\n",
        "\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = dec_states\n",
        "\n",
        "    print(decoded_translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-vDeCfVM3gHE",
        "outputId": "b4d9043c-293c-454a-b7d7-b68683f60ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter question : hekko\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            " with feel the caught the course from the police we have to go i told them\n",
            "Enter question : руддщ\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            " with feel the caught the course from the police we have to go i told them\n",
            "Enter question : hello\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            " once in feel the imagine does you know me\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-152-2d3643569502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mstates_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter question : '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mempty_target_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mempty_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_SIZE = 256 # Размерность скрытого состояния LSTM\n",
        "EMB_SIZE = 256 # размерность эмбеддингов (и для входных и для выходных цепочек)\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(VOCAB_SIZE, EMB_SIZE, mask_zero=True)\n",
        "        self.lstm = tf.keras.layers.LSTM(H_SIZE, return_sequences=False, return_state=True)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        out = self.embed(inputs)\n",
        "        _, h, c = self.lstm(out)\n",
        "        state = [h, c]\n",
        "        return state\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(VOCAB_SIZE, EMB_SIZE, mask_zero=True)\n",
        "        self.lstm = tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(VOCAB_SIZE, activation='softmax')\n",
        "        \n",
        "    def call(self, inputs, init_state):\n",
        "        out = self.embed(inputs)\n",
        "        out, h, c = self.lstm(out, initial_state=init_state)\n",
        "        out = self.fc(out)\n",
        "        state = [h, c]\n",
        "        return out, state"
      ],
      "metadata": {
        "id": "rNACJ3Os5Iwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Encoder()\n",
        "decoder_model = Decoder()\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "enc_state = encoder_model(encoder_inputs)\n",
        "decoder_outputs, _ = decoder_model(decoder_inputs, enc_state)\n",
        "\n",
        "seq2seq = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "loss = tf.losses.SparseCategoricalCrossentropy()\n",
        "seq2seq.compile(optimizer='rmsprop', loss=loss)\n",
        "seq2seq.summary()"
      ],
      "metadata": {
        "id": "M8tarOGi6olY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1e43dd-7ed3-4ee1-b8c9-e92f47c7d959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_27\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_90 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_91 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_15 (Encoder)           [(None, 256),        2557952     ['input_90[0][0]']               \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " decoder_15 (Decoder)           ((None, None, 7940)  4598532     ['input_91[0][0]',               \n",
            "                                , [(None, 256),                   'encoder_15[0][0]',             \n",
            "                                 (None, 256)])                    'encoder_15[0][1]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,156,484\n",
            "Trainable params: 7,156,484\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 150\n",
        "\n",
        "seq2seq.fit([encoder_input_data, decoder_input_data],\n",
        "            decoder_output,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "miFG7JjMFn1H",
        "outputId": "c382b3b7-56a1-499b-88a5-16dbcab1c030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.1271\n",
            "Epoch 2/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.1213\n",
            "Epoch 3/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.1155\n",
            "Epoch 4/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.1103\n",
            "Epoch 5/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.1052\n",
            "Epoch 6/150\n",
            "74/74 [==============================] - 5s 71ms/step - loss: 0.1003\n",
            "Epoch 7/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0954\n",
            "Epoch 8/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0908\n",
            "Epoch 9/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0867\n",
            "Epoch 10/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0817\n",
            "Epoch 11/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0776\n",
            "Epoch 12/150\n",
            "74/74 [==============================] - 5s 71ms/step - loss: 0.0737\n",
            "Epoch 13/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0698\n",
            "Epoch 14/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0658\n",
            "Epoch 15/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0624\n",
            "Epoch 16/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0587\n",
            "Epoch 17/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0553\n",
            "Epoch 18/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0522\n",
            "Epoch 19/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0491\n",
            "Epoch 20/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0462\n",
            "Epoch 21/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0433\n",
            "Epoch 22/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0408\n",
            "Epoch 23/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0383\n",
            "Epoch 24/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0359\n",
            "Epoch 25/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0336\n",
            "Epoch 26/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0315\n",
            "Epoch 27/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0295\n",
            "Epoch 28/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0272\n",
            "Epoch 29/150\n",
            "74/74 [==============================] - 5s 59ms/step - loss: 0.0256\n",
            "Epoch 30/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0240\n",
            "Epoch 31/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0223\n",
            "Epoch 32/150\n",
            "74/74 [==============================] - 6s 77ms/step - loss: 0.0209\n",
            "Epoch 33/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0195\n",
            "Epoch 34/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0181\n",
            "Epoch 35/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0170\n",
            "Epoch 36/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0157\n",
            "Epoch 37/150\n",
            "74/74 [==============================] - 5s 59ms/step - loss: 0.0146\n",
            "Epoch 38/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0136\n",
            "Epoch 39/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0128\n",
            "Epoch 40/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0120\n",
            "Epoch 41/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0112\n",
            "Epoch 42/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0104\n",
            "Epoch 43/150\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0099\n",
            "Epoch 44/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0091\n",
            "Epoch 45/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0086\n",
            "Epoch 46/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0081\n",
            "Epoch 47/150\n",
            "74/74 [==============================] - 5s 74ms/step - loss: 0.0078\n",
            "Epoch 48/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0071\n",
            "Epoch 49/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0068\n",
            "Epoch 50/150\n",
            "74/74 [==============================] - 5s 74ms/step - loss: 0.0068\n",
            "Epoch 51/150\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0063\n",
            "Epoch 52/150\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0058\n",
            "Epoch 53/150\n",
            "74/74 [==============================] - 6s 76ms/step - loss: 0.0055\n",
            "Epoch 54/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0054\n",
            "Epoch 55/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0052\n",
            "Epoch 56/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0050\n",
            "Epoch 57/150\n",
            "74/74 [==============================] - 5s 73ms/step - loss: 0.0047\n",
            "Epoch 58/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0045\n",
            "Epoch 59/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0044\n",
            "Epoch 60/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0042\n",
            "Epoch 61/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0042\n",
            "Epoch 62/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0040\n",
            "Epoch 63/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0038\n",
            "Epoch 64/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0037\n",
            "Epoch 65/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0036\n",
            "Epoch 66/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0035\n",
            "Epoch 67/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0035\n",
            "Epoch 68/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0034\n",
            "Epoch 69/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0034\n",
            "Epoch 70/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0032\n",
            "Epoch 71/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0032\n",
            "Epoch 72/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0032\n",
            "Epoch 73/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0031\n",
            "Epoch 74/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0030\n",
            "Epoch 75/150\n",
            "74/74 [==============================] - 6s 77ms/step - loss: 0.0029\n",
            "Epoch 76/150\n",
            "74/74 [==============================] - 5s 71ms/step - loss: 0.0029\n",
            "Epoch 77/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0029\n",
            "Epoch 78/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0028\n",
            "Epoch 79/150\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0027\n",
            "Epoch 80/150\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0028\n",
            "Epoch 81/150\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0027\n",
            "Epoch 82/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0027\n",
            "Epoch 83/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0027\n",
            "Epoch 84/150\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0026\n",
            "Epoch 85/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0026\n",
            "Epoch 86/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0026\n",
            "Epoch 87/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0025\n",
            "Epoch 88/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0025\n",
            "Epoch 89/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0025\n",
            "Epoch 90/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0024\n",
            "Epoch 91/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0024\n",
            "Epoch 92/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0024\n",
            "Epoch 93/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0024\n",
            "Epoch 94/150\n",
            "74/74 [==============================] - 5s 68ms/step - loss: 0.0024\n",
            "Epoch 95/150\n",
            "74/74 [==============================] - 5s 74ms/step - loss: 0.0025\n",
            "Epoch 96/150\n",
            "74/74 [==============================] - 5s 67ms/step - loss: 0.0024\n",
            "Epoch 97/150\n",
            " 3/74 [>.............................] - ETA: 3s - loss: 0.0020"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-167-2ea75f072c1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m seq2seq.fit([encoder_input_data, decoder_input_data], padded_answers,\n\u001b[0m\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           epochs=EPOCHS)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq.save('model_seq2seq_chat.h5')"
      ],
      "metadata": {
        "id": "yuLXTjPOwrr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инференс\n",
        "for _ in range(10):\n",
        "    encoder_states = encoder_model(str_to_tokens(input('Enter question : ')))\n",
        "    \n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index.get('<start>')\n",
        "\n",
        "    decoded_sentence = ''\n",
        "    stop_condition = False\n",
        "    while not stop_condition:\n",
        "        output_tokens, decoder_states = decoder_model(empty_target_seq, encoder_states)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index)\n",
        "        \n",
        "        if sampled_word != '<end>':\n",
        "          decoded_sentence += ' {}'.format(sampled_word)\n",
        "\n",
        "        if (sampled_word == '<end>' or len(decoded_sentence) > maxlen_answers):\n",
        "            stop_condition = True\n",
        "\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_token_index\n",
        "        encoder_states = decoder_states\n",
        "\n",
        "    print(decoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "6seFmdV9FlGN",
        "outputId": "27ccf57a-f240-41bb-b055-a529e2d74763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter question : hello\n",
            " mrs mathews it is thomas do you remember i was there a few weeks ago asking about your daughter\n",
            "Enter question : did you change\n",
            " i was at hand it\n",
            "Enter question : how are you\n",
            " i am okay honey i am okay\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-172-480c12312f9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# seq2seq inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mencoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter question : '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mempty_target_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "RNN-Chat-Bot.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}